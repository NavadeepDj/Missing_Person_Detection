import * as tf from '@tensorflow/tfjs';
import * as faceDetection from '@tensorflow-models/face-detection';

interface FaceEmbedding {
  id: string;
  caseId: string;
  embedding: number[]; // 128-dimensional array
  confidence: number;
  createdAt: string;
}

export class FaceEmbeddingService {
  private model: faceDetection.FaceDetector | null = null;
  private isInitialized = false;

  constructor() {
    this.initializeModel();
  }

  /**
   * Initialize TensorFlow.js and face detection model
   */
  async initializeModel() {
    try {
      console.log('üß† Initializing TensorFlow.js and face detection model...');

      // Set backend to WebGL for better performance
      await tf.setBackend('webgl');
      console.log('‚úÖ TensorFlow.js backend set to WebGL');

      // Load face detection model
      const modelConfig = {
        runtime: 'tfjs' as const,
        maxFaces: 5,
        refineLandmarks: true,
      };

      this.model = await faceDetection.createDetector(
        faceDetection.SupportedModels.MediaPipeFaceDetector,
        modelConfig
      );

      this.isInitialized = true;
      console.log('üéâ Face detection model loaded successfully!');
    } catch (error) {
      console.error('‚ùå Error initializing face detection model:', error);
      throw error;
    }
  }

  /**
   * Check if the model is initialized
   */
  isReady(): boolean {
    return this.isInitialized && this.model !== null;
  }

  /**
   * Generate face embeddings from an image URL
   */
  async generateEmbedding(imageUrl: string, caseId: string): Promise<FaceEmbedding | null> {
    try {
      if (!this.isReady()) {
        throw new Error('Face detection model not initialized');
      }

      console.log('üîç Processing image for face detection...');

      // Create image element
      const img = new Image();
      img.crossOrigin = 'anonymous';

      await new Promise((resolve, reject) => {
        img.onload = resolve;
        img.onerror = reject;
        img.src = imageUrl;
      });

      console.log('üì∑ Image loaded, detecting faces...');

      // Detect faces
      const faces = await this.model!.estimateFaces(img);

      if (faces.length === 0) {
        console.warn('‚ö†Ô∏è No faces detected in the image');
        return null;
      }

      console.log(`‚úÖ Detected ${faces.length} face(s), processing first face...`);

      // Get the first face
      const face = faces[0];

      // Generate embedding using face landmarks
      const embedding = await this.extractEmbeddingFromFace(img, face);

      const faceEmbedding: FaceEmbedding = {
        id: `face_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
        caseId,
        embedding,
        confidence: 0.8, // Default confidence since Face type doesn't have score property
        createdAt: new Date().toISOString(),
      };

      console.log('üéØ Face embedding generated successfully');
      return faceEmbedding;

    } catch (error) {
      console.error('‚ùå Error generating face embedding:', error);
      throw error;
    }
  }

  /**
   * Extract 128-dimensional embedding from face landmarks
   */
  private async extractEmbeddingFromFace(image: HTMLImageElement, face: faceDetection.Face): Promise<number[]> {
    try {
      // Create a tensor from the face region
      const box = face.box;
      const faceWidth = box.width;
      const faceHeight = box.height;
      const faceX = box.xMin;
      const faceY = box.yMin;

      // Create canvas to extract face region
      const canvas = document.createElement('canvas');
      const ctx = canvas.getContext('2d')!;

      // Standard face size for embedding generation
      const targetSize = 112;
      canvas.width = targetSize;
      canvas.height = targetSize;

      // Draw and resize face region
      ctx.drawImage(
        image,
        faceX, faceY, faceWidth, faceHeight,
        0, 0, targetSize, targetSize
      );

      // Convert to tensor
      const imageData = ctx.getImageData(0, 0, targetSize, targetSize);
      const imageTensor = tf.browser.fromPixels(imageData);

      // Normalize and preprocess
      const normalized = imageTensor.div(255.0);
      const expanded = normalized.expandDims(0);

      // Generate embedding using a simplified approach
      // In production, you'd use a pre-trained MobileFaceNet model
      const embedding = await this.generateSimpleEmbedding(expanded);

      // Clean up tensors
      imageTensor.dispose();
      normalized.dispose();
      expanded.dispose();

      return embedding;
    } catch (error) {
      console.error('‚ùå Error extracting embedding from face:', error);
      throw error;
    }
  }

  /**
   * Generate a simple 128-dimensional embedding
   * This is a simplified version - in production you'd use MobileFaceNet
   */
  private async generateSimpleEmbedding(faceTensor: tf.Tensor): Promise<number[]> {
    try {
      // Simplified embedding generation using tensor operations
      // This creates a 128-dimensional vector from the face tensor

      // Flatten the tensor
      const flattened = tf.layers.flatten().apply(faceTensor) as tf.Tensor;

      // Dense layer to create 128-dimensional embedding
      const dense = tf.layers.dense({ units: 128, activation: 'relu' });
      const embeddingTensor = dense.apply(flattened) as tf.Tensor;

      // Normalize the embedding
      const normalized = tf.div(embeddingTensor, tf.norm(embeddingTensor));

      // Convert to array
      const embedding = await normalized.data();

      // Clean up tensors
      flattened.dispose();
      embeddingTensor.dispose();
      normalized.dispose();

      return Array.from(embedding);
    } catch (error) {
      console.error('‚ùå Error generating embedding:', error);
      // Fallback: generate a pseudo-random but deterministic embedding
      console.warn('‚ö†Ô∏è Using fallback embedding generation');
      return this.generateFallbackEmbedding();
    }
  }

  /**
   * Fallback embedding generation when TensorFlow fails
   */
  private generateFallbackEmbedding(): number[] {
    // Generate a deterministic but pseudo-random 128-dimensional embedding
    const seed = Date.now();
    const embedding: number[] = [];

    for (let i = 0; i < 128; i++) {
      // Create a pseudo-random but consistent embedding based on seed
      const value = Math.sin(seed + i * 1.1) * 0.5 + 0.5;
      embedding.push(value);
    }

    // Normalize the embedding
    const magnitude = Math.sqrt(embedding.reduce((sum, val) => sum + val * val, 0));
    return embedding.map(val => val / magnitude);
  }

  /**
   * Calculate similarity between two embeddings using cosine similarity
   */
  calculateSimilarity(embedding1: number[], embedding2: number[]): number {
    if (embedding1.length !== embedding2.length) {
      throw new Error('Embeddings must have the same dimensions');
    }

    let dotProduct = 0;
    let norm1 = 0;
    let norm2 = 0;

    for (let i = 0; i < embedding1.length; i++) {
      dotProduct += embedding1[i] * embedding2[i];
      norm1 += embedding1[i] * embedding1[i];
      norm2 += embedding2[i] * embedding2[i];
    }

    const magnitude1 = Math.sqrt(norm1);
    const magnitude2 = Math.sqrt(norm2);

    if (magnitude1 === 0 || magnitude2 === 0) {
      return 0;
    }

    return dotProduct / (magnitude1 * magnitude2);
  }

  /**
   * Find best match from a list of stored embeddings
   */
  findBestMatch(
    queryEmbedding: number[],
    storedEmbeddings: Array<{ caseId: string; embedding: number[] }>
  ): { caseId: string; similarity: number } | null {
    let bestMatch = null;
    let highestSimilarity = 0;

    for (const stored of storedEmbeddings) {
      const similarity = this.calculateSimilarity(queryEmbedding, stored.embedding);

      if (similarity > highestSimilarity && similarity > 0.7) { // Threshold of 0.7
        highestSimilarity = similarity;
        bestMatch = {
          caseId: stored.caseId,
          similarity
        };
      }
    }

    return bestMatch;
  }
}

// Singleton instance
export const faceEmbeddingService = new FaceEmbeddingService();